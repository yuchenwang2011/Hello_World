Docker lifecycle 3 stages:
1. image
    An image is a lightweight, stand-alone, 
    executable package that includes everything needed to run a piece of software, 
    including the code, a runtime, libraries, environment variables, and config files.
2. container
    A container is a runtime instance of an image—what the image becomes in memory when actually executed. 
    It runs completely isolated from the host environment by default, only accessing host files and ports if configured to do so.
3. repository
4. Swarm is a group of machines that are running Docker and joined into a cluster.


One/many containers run in a service, a service runs in a stack
In production, app runs as a service



Follow the official installation guide on 
   https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/#os-requirements
a translated version
   https://yeasy.gitbooks.io/docker_practice/content/install/ubuntu.html
All the docker official documents are here
   https://docs.docker.com/engine/installation/

On Ubuntu

=================First install a Docker Repo==========================
1. Update apt packages 
     sudo apt-get update
2. Remove old version of docker engine
     sudo apt-get remove docker docker-engine docker.io
3. Install HTTPS certificate
   sudo apt-get install \
    apt-transport-https \
    ca-certificates \
    curl \
    software-properties-common
4. Add a Key to secure download
     curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
   To check the key is valid, by command
     sudo apt-key fingerprint 0EBFCD88
   Verify the output has 9DC8 5822 9FC7 DD38 854A  E2D8 8D81 803C 0EBF CD88
5. Install the repo
   sTo check this:
     docker service lsTo check this:
     docker service lsudo add-apt-repository \
    "deb [arch=amd64] https://download.docker.com/linux/ubuntu \
    $(lsb_release -cs) \
    stable"  
=================Second install a Docker CE (CE is free for 3 months, EE needs to pay)=========
1. Update apt package we already done
    sudo apt-get update
2. Install the latest version of Docker CE, it takes about 5 mins
    sudo apt-get install docker-ce
   If you want to use a specific version in production, you can use this command
    sudo apt-get install docker-ce=<VERSION>
3. After installation, you need start docker, two commands:
    sudo systemctl enable docker
    sudo systemctl start docker
4. Verify that docker has installed correctly, hello world:
    sudo docker run hello-world
   This command downloads a test image and runs it in a container. When the container runs, 
   it prints an informational message and exits.
5. This step is for linux user because in the current docker group, you only have a root user,
   to add your current user into docker group(means you don't need "sudo" every time you use docker command)
   a. add a docker group (which may already exists, doesn't matter)
        sudo groupadd docker
   b. add current user to the group
        sudo usermod -aG docker $USER
   c. exit the terminal and re-enter (or restart the VM), try run hello world without using "sudo"
        docker run hello-world
   d. add docker to start automatically when the system reboots
        sudo systemctl enable docker
      To disable, use this
        sudo systemctl disable docker
6. If you want to uninstall Docker CE, you can 
     sudo apt-get purge docker-ce
   To remove all the images, containeres, volumes (those won't be deleted automatically), you can 
     sudo rm -rf /var/lib/docker
=================================How to use Docker==========================================
1. You can register a docker ID 
     https://cloud.docker.com/
2. Then login docker, run command:
     docker login
3. Create a Dockerfile
     mkdir app
     cd app 
   Create a file called "Dockerfile"
   Then copy and paste following to the file and save
     # Use an official Python runtime as a parent image
     FROM python:2.7-slim
     
     # Set the working directory to /app
     WORKDIR /app
     
     # Copy the current directory contents into the container at /app
     ADD . /app
     
     # Install any needed packages specified in requirements.txt
     RUN pip install --trusted-host pypi.python.org -r requirements.txt
     
     # Make port 80 available to the world outside this container
     EXPOSE 80
     
     # Define environment variable
     ENV NAME World
     
     # Run app.py when the container launches
     CMD ["python", "app.py"]
    
4. Create two more files, requirements.txt and app.py in the same folder
   requirements.txt content:
     Flask
     Redis
   app.py content:
     from flask import Flask
     from redis import Redis, RedisError
     import os
     import socket
     
     # Connect to Redis
     redis = Redis(host="redis", db=0, socket_connect_timeout=2, socket_timeout=2)
     
     app = Flask(__name__)
     
     @app.route("/")
     def hello():
         try:
             visits = redis.incr("counter")
         except RedisError:
             visits = "<i>cannot connect to Redis, counter disabled</i>"
     
         html = "<h3>Hello {name}!</h3>" \
                "<b>Hostname:</b> {hostname}<br/>" \
                "<b>Visits:</b> {visits}"
         return html.format(name=os.getenv("NAME", "world"), hostname=socket.gethostname(), visits=visits)
     
     if __name__ == "__main__":
         app.run(host='0.0.0.0', port=80)

5. Build the app by running command, where -t means gives the buidl a name reference, the " ." is necessary
   where the "." means to save to current directory
     docker build -t friendlyhello .
   After build the app, you can check the images you have 
6. Run the app, mapping your machine’s port 4000 to the container’s published port 80 using -p:
     docker run -p 4000:80 friendlyhello
   You should see a message that Python is serving your app at http://0.0.0.0:80. 
   But that message is coming from inside the container, which doesn’t know you mapped port 80 of that container to 4000, 
   making the correct URL http://localhost:4000. Go to that URL in a web browser 
   to see the display content served up on a web page.
   You can also get the same content in shell:
     curl http://localhost:4000
   Type Ctrl + C to exit
7. A way to exit decently
   Run the image in background
     docker run -d -p 4000:80 friendlyhello
   Using the string it gives, you can check it is running now by
     docker container ls
   To stop it, copy the hash string, then:
     docker container stop 1fa4ab2cf395
=====================================Share the image================================
1. Login to your registry (your account) by:
     docker login
   Each registry can have many repository, each repository can have many images
2. Tag the image, the naming convention is username/repository:tag, so the command is like:
     docker tag image username/repository:tag
   For example: 
     docker tag friendlyhello yuchenwang/get-started:part2
   Then you can check it by using:
     docker images
3. Publish the image, upload your tagged image to the repository:
     docker push username/repository:tag
   You can always push latest images to this repository by:
     docker push yuchenwang/get-started:tagname
   After push, you can find it in your repo when you login your own docker account. Also now you can pull the image from
   anywhere by visiting here to get the pull command:
     https://hub.docker.com/
4. From now on, you can use docker run and run your app on any machine with this command:
     docker run -p 4000:80 username/repository:tag
   If the image isn’t available locally on the machine, Docker will pull it from the repository.
5. To remove a container from local machine
      docker container rm <hash> 
   To remove a image from local machine
      docker image rm <image id>
======================================Services=====================================
1. First install docker-composer
   Follow this page https://docs.docker.com/compose/install/#install-compose  Linux version
     sudo curl -L https://github.com/docker/compose/releases/download/1.18.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose
     sudo chmod +x /usr/local/bin/docker-compose
2. Compose also needs "bash completion", so you also need install it
    sudo curl -L https://raw.githubusercontent.com/docker/compose/1.18.0/contrib/completion/bash/docker-compose -o /etc/bash_completion.d/docker-compose
3. Test the installation:
    docker-compose --version
4. Uninstall docker-composer
    sudo rm /usr/local/bin/docker-compose
5. Create a docker-compose.yml file, modify the template below a little bit, but before creating the file, you need
   first have pushed your image to registry
    version: "3"
    services:
      web:
        # replace username/repo:tag with your name and image details
        image: yuchenwang/get-started:part2
        deploy:
          replicas: 5
          resources:
            limits:
              cpus: "0.1"
              memory: 50M
          restart_policy:
            condition: on-failure
        ports:
          - "80:80"
        networks:
          - webnet
    networks:
      webnet:
6. Then run this load-balanced app by:, which makes the current node a manager 
     docker swarm init
7. Now let’s run it. You have to give your app a name. Here, it is set to getstartedlab
     docker stack deploy -c docker-compose.yml getstartedlab
8. Our single service stack is running 5 container instances of our deployed image on one host. To check this:
     docker service ls
9. To check all the containers/tasks currently running under the service:
     docker service ps getstartedlab_web
   Or simply all the containers/tasks running
     docker container ls -q
   You can check they are running by calling your website:
     curl -4 http://localhost
   To check the stack:
     docker stack ls 
10. you can change the replica number in yml file and run command in step 7 the stack deploy command
11. Take the app down:
       docker stack rm getstartedlab
12. Take the swarm down:
       docker swarm leave --force
========================================Swarms====================================================
1. First install Docker Machine:
   https://docs.docker.com/machine/install-machine/#install-machine-directly

   curl -L https://github.com/docker/machine/releases/download/v0.13.0/docker-machine-`uname -s`-`uname -m` >/tmp/docker-machine && \
   chmod +x /tmp/docker-machine && \
   sudo cp /tmp/docker-machine /usr/local/bin/docker-machine
2. Check the Machine version to verify installation successfully
     docker-machine version
3. Install bash completion script, check the version first (better follow the official doc)
     in the /usr/local/etc/bash_completion.d , add:
     scripts=( docker-machine-prompt.bash docker-machine-wrapper.bash docker-machine.bash ); for i in "${scripts[@]}"; do sudo wget https://raw.githubusercontent.com/docker/machine/v0.13.0/contrib/completion/bash/${i} -P /etc/bash_completion.d; done
4. In ~/.bashrc file, add:
     PS1='[\u@\h \W$(__docker_machine_ps1)]\$ '
5. To remove Docker Machine
     rm $(which docker-machine)
6. Create two VMs, (not possible if your machine is already a VM)
     docker-machine create --driver virtualbox myvm1
     docker-machine create --driver virtualbox myvm2
   To remove the machines you can
     docker-machine rm myvm1
     docker-machine rm myvm2
7. To check the status of your docker VMs, you can
     docker-machine ls
8. Make the first VM a swarm manager
     docker-machine ssh myvm1 "docker swarm init --advertise-addr <myvm1 ip>"
9. Let the second VM join the swarm as a worker
     docker-machine ssh myvm2 "docker swarm join \
      --token <token> \
      <ip>:2377"
10. Check all the nodes on the swarm:
     docker-machine ssh myvm1 "docker node ls"
11. Leave the swarm, you can:
     docker swarm leave from each node.
12. Configure a docker-machine shell to the swarm manager, thus you can use your local yml file to talk to the swarm manager
     docker-machine env myvm1
    Then
     eval $(docker-machine env myvm1)
    Then, you can find the myvm1 is shown with an active star
     docker-machine ls

    (to unbind it, unset the docker-machine environment variables in your current shell, you can
			eval $(docker-machine env -u)
    )
    
========================================Deploy your APP on the swarm==============================
Now that you have myvm1, you can use its powers as a swarm manager to deploy your app 
by using the same docker stack deploy command you used in part 3 to myvm1, and your local copy of docker-compose.yml.
1. Now you can deploy your app on myvm1 directly
     docker stack deploy -c docker-compose.yml getstartedlab
2. You can verify that they are running on VMs not on your local machine, you can check
     docker stack ps getstartedlab
3. Now you can access your app from both ips of the two VMs, or visit through browser (no port number)
     curl http://192.168.99.100
4. From here you can do everything you learned above.
    a. Scale the app by changing the docker-compose.yml file.
    b. Change the app behavior by editing code, then rebuild, and push the new image. 
    c. In either case, simply run docker stack deploy again to deploy these changes.
    You can join any machine, physical or virtual, 
    to this swarm, using the same docker swarm join command you used on myvm2, and capacity will be added to your cluster. 
    Just run docker stack deploy afterwards, and your app will take advantage of the new resources.
5. You can tear down the stack by
     docker stack rm getstartedlab
6. You can remove the swarm by
     docker-machine ssh myvm2 "docker swarm leave" on the worker
     docker-machine ssh myvm1 "docker swarm leave --force"
7. When you shutdown your local host, the VMs will also stop, to restart them, you can
     docker-machine start <machine-name>


we want finally install a docker server on a remote server https://www.digitalocean.com/
then build a local container
then upload/publish the local image to remote server
